
// Make available cfg parameters & specify which algorithm is to be used for duplicate track removal.
template <class T>
void KillDupTrks<T>::init(const Settings* settings, unsigned int dupTrkAlg)
{
	settings_ = settings; 
	
	dupTrkAlg_                 = dupTrkAlg;
	dupTrkMinIndependent_      = settings->dupTrkMinIndependent();
	dupTrkMinCommonHitsLayers_ = settings->dupTrkMinCommonHitsLayers();
	dupTrkChiSqCut_            = settings->dupTrkChiSqCut();
	dupMaxQOverPtScan_         = settings->dupMaxQOverPtScan();
	dupMaxPhi0Scan_            = settings->dupMaxPhi0Scan();
	dupMaxZ0Scan_              = settings->dupMaxZ0Scan();
	dupMaxTanLambdaScan_       = settings->dupMaxTanLambdaScan();

	enableMerge2x2_  = settings->enableMerge2x2();  //Parameters for HT array...
	minInvPtToMerge2x2_ = 1./settings->maxPtToMerge2x2();
	maxAbsQoverPtAxis_  = 1./settings->houghMinPt(); // Max. |q/Pt| covered by  HT array.
	nBinsQoverPtAxis_   = settings->houghNbinsPt();  // No. of bins in HT array in q/Pt.

	// Calculate a few more...
	if (enableMerge2x2_) // Have finer binning in centre of array
	  { float binSizeQoverPtAxis = 2*maxAbsQoverPtAxis_ / nBinsQoverPtAxis_;
	    float fMergeBins = (maxAbsQoverPtAxis_ - minInvPtToMerge2x2_)/(2.*binSizeQoverPtAxis);
	    minFineBin_ = 2 * min( (unsigned int)(floor(fMergeBins)), (nBinsQoverPtAxis_/4) );
	    maxFineBin_ = nBinsQoverPtAxis_ - minFineBin_ - 1;
	  }
	else // Set limits to whole array
	  { minFineBin_ = 0; // Have to be careful, they are unsigned...
	    maxFineBin_ = nBinsQoverPtAxis_;
	  }
}

// Tests if cells are adjacent in q/pT
template <class T>
bool KillDupTrks<T>::isNextQoverPt(std::pair<unsigned int, unsigned int> i, std::pair<unsigned int, unsigned int> j) const
{ unsigned int iF = i.first, jF = j.first;
  if ((iF < minFineBin_) || (iF > maxFineBin_)) { ++iF;} // Adjustment for double-width bins
  if ((jF - iF) > 1) {return false;} // Must be ordered in q/pT
  if (i.second == j.second) { return true;} // Adjacent columns in same row
  return false; //Not correct
}

// Tests if cells are adjacent in q/pT AND phi0
template <class T>
bool KillDupTrks<T>::isAdjacentCell(std::pair<unsigned int, unsigned int> i, std::pair<unsigned int, unsigned int> j) const
{ unsigned int iF = i.first, jF = j.first;
  bool isFine = true;
  if ((iF < minFineBin_) || (iF > maxFineBin_)) { ++iF; isFine = false;} // Adjustment for double-width bins
  if ((jF - iF) > 1) {return false;} // Ordered in q/pT
  if (abs( int(i.second) - int(j.second) ) < (isFine ? 2: 3)) { return true;} // Adjacent columns in same row
  return false; //Not correct
}




// Eliminate duplicate tracks from the input collection, and so return a reduced list of tracks.
template <class T>
vector<T> KillDupTrks<T>::filter(const vector<T>& vecTracks) const
{
	// Short-circuit the calculation for trivial cases
	if (vecTracks.size() == 0 || vecTracks.size() == 1)
	{
		return vecTracks;
	}
	
	// Choose which algorithm to run, based on parameter dupTrkAlg_.
	switch (dupTrkAlg_)
	{
		// Do no filtering at all in the 0 case
		case  0: return                vecTracks; break;
		case  1: return  filterAlg1( vecTracks ); break;
		case  2: return  filterAlg2( vecTracks ); break;
		case  3: return  filterAlg3( vecTracks ); break;
		case  4: return  filterAlg4( vecTracks ); break;
		case  5: return  filterAlg5( vecTracks ); break;
		case  6: return  filterAlg6( vecTracks ); break;
		case  7: return  filterAlg7( vecTracks ); break;
		case  8: return  filterAlg8( vecTracks ); break;
		case  9: return  filterAlg9( vecTracks ); break;
		case 10: return filterAlg10( vecTracks ); break;
		case 11: return filterAlg11( vecTracks ); break;
		case 12: return filterAlg12( vecTracks ); break;
		case 13: return filterAlg13( vecTracks ); break;
		case 14: return filterAlg14( vecTracks ); break;
		case 15: return filterAlg15( vecTracks ); break;
		case 16: return filterAlg16( vecTracks ); break;
		case 17: return filterAlg17( vecTracks ); break;
		case 18: return filterAlg18( vecTracks ); break;
		case 19: return filterAlg19( vecTracks ); break;
		default: throw cms::Exception("KillDupTrks: Option DupTrkAlg in cfg has invalid value.");
	}
	
	// We should never end up here
	return vecTracks;
}



//=== A specific algorithm for filtering duplicate tracks.
//=== Selects only a single track, based on the number of stubs & number of layers with stubs on the track.

template <class T>
vector<T> KillDupTrks<T>::filterAlg1(const vector<T>& vecTracks) const
{
	const bool debug = false;
	
	
	vector<T> vecTracksFiltered;
	
	float bestQuality = 0;
	const T* bestTrk = nullptr;
	
	unsigned int nTrk = 0;
	bool real = false;
	
	for (const T& trk : vecTracks)
	{
		
		// Define quality flag for choosing best track, taking into account both the number of stubs
		// on the track and the number of layers that these are in.
		float quality = 100000*trk.getNumLayers() + 100*trk.getNumStubs();
		
		// In case two tracks have identical quality, choose the one with smallest |z0|, unless this is not
		// available, (because we have a 2D r-phi track), in which case use the track with largest Pt.
		// (If this is not done, first track is chosen, which tends to be one with most -ve helix
		// parameter, giving an annoying apparent bias in the helix resolution plots).
		try
		{
			quality -= fabs(trk.qOverPt());
		}
		catch (cms::Exception& ce)
		{
			// This must be a 2D r-phi track.
			quality -= fabs(trk.z0());      
		}
		
		if (bestQuality < quality)
		{
			bestQuality = quality;
			bestTrk = &trk;
		}

		// Debug printout.
		if (debug)
		{
			try
			{
				cout<<"DUP TRK "<<++nTrk<<" "<<(trk.getMatchedTP() != nullptr)<<" "<<quality<<" "<<trk.getCellLocationRphi().first<<" "<<trk.getCellLocationRphi().second<<endl;
			}
			catch (cms::Exception& ce)
			{
				// This must be a 2D r-z track.
				cout<<"DUP TRK "<<++nTrk<<" "<<(trk.getMatchedTP() != nullptr)<<" "<<quality<<" "<<trk.getCellLocationRz().first<<" "<<trk.getCellLocationRz().second<<endl;
			}
			
			if (trk.getMatchedTP() != nullptr)
				real = true;
		}
	}
	
	if (bestQuality > 0)
		vecTracksFiltered.push_back(*bestTrk);
	
	// Debug printout.
	if (debug && bestQuality > 0 && real == true && bestTrk->getMatchedTP() == nullptr)
		cout<<"GENUINE TRACK PRESENT, BUT KILLDUPTRKS MISSED IT!"<<endl;
	
	return vecTracksFiltered;
}



//=== An algorithm to remove candidates with exactly the same stubs as another
//=== Based on Stub index() -- assumes they are ordered!  idr 9/7/15

template <class T>
vector<T> KillDupTrks<T>::filterAlg2(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< unsigned int > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< unsigned int > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back(myStub->index());
		}
		
		// now necessary due to seed-filter disordering stubs
		std::sort(stubList.begin(),stubList.end());
		
		candList.push_back(stubList);
	}
	
	
	unsigned int i = 0;
	
	std::vector< unsigned int > indices; // to avoid expense of manipulating candidate vector
	for (std::size_t i = 0; i< candList.size(); ++i)
		{ indices.push_back(i);
		}

	i=0;
	while (i < (candList.size()-1)) // Loop through vector
		{ unsigned int j = i+1;
			while (j < candList.size()) // Check rest of candidates
	{ if (candList[j].size() == candList[i].size()) // possible match
			{ bool dupe = true;
				for (unsigned int k = 0; k<candList[i].size(); ++k)
		{ if (candList[j][k] != candList[i][k])
				{ dupe = false;  // no, not an exact match
					break;
				}
		}
				if (dupe)
		{  printKill(dupTrkAlg_,  j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
			candList.erase(candList.begin()+j); // remove duplicate
			indices.erase(indices.begin()+j);   // and adjust index array
			
		}
				else
		{ ++j;} //try next candidate
			}
		else
			{ ++j;} //not same size, go to next
	}
			++i; // compared all, now look for dupes of next candidate
		}

	for (i = 0; i<indices.size(); ++i)
		{ vecTracksFiltered.push_back(vecTracks.at(indices[i])); // copy non-dupes to output
		}

	return vecTracksFiltered;
}



// A specific algorithm for filtering duplicates
// Pairwise candidate comparison, removes tracks with fewer than N independent stubs
// Implementing OSU algorithm, keep tracks with N or more unique stubs (default 3)

template <class T>
vector<T> KillDupTrks<T>::filterAlg3(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	
	// vector (corresponding to indices for candidate tracks)
	std::vector< std::vector< unsigned int > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		std::vector< unsigned int > stubList;
		for (const auto & myStub: stubs)
		{
			stubList.push_back(myStub->index());
		}
		
		std::sort(stubList.begin(),stubList.end()); // now necessary due to seed-filter disordering stubs
		
		candList.push_back(stubList);
	}

	
	unsigned int i = 0;

	std::vector< unsigned int > indices; // to avoid expense of manipulating candidate vector
	for (i = 0; i< candList.size(); ++i)
		{ indices.push_back(i);
		}

	i=0;
	while (i < (candList.size()-1)) // Loop through vector
		{ unsigned int j = i+1;
			while (j < candList.size()) // Check rest of candidates
	{ unsigned int countI = 0, countJ = 0, indxI = 0, indxJ = 0;
		unsigned int lenI = candList[i].size(), lenJ = candList[j].size();
		while ((indxI<lenI) && (indxJ<lenJ))
			{ if (candList[i][indxI] == candList[j][indxJ])
		{ ++indxI; ++indxJ;} //match
				else
		{ if (candList[i][indxI] < candList[j][indxJ]) // In i, not j
				{ ++indxI; ++countI;}
			else
				{ ++indxJ; ++countJ;} // In j, not i
		}
			}
		if (indxI < lenI) //adjust if either not all checked
			{ countI += (lenI-indxI); }
		if (indxJ < lenJ)
			{ countJ += (lenJ-indxJ); }

		if (countI >= dupTrkMinIndependent_)
			{ if (countJ >= dupTrkMinIndependent_)
		{ ++j;} // Keep both, next candidate
				else  // Delete j
		{ printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
			candList.erase(candList.begin()+j);
			indices.erase(indices.begin()+j);
		}
			} // Now countI < dupTrkMinIndependent_, countJ unknown
		else
			{ if (countJ >= dupTrkMinIndependent_) // j wins because i doesn't have enough candidates
		{ printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
			candList.erase(candList.begin()+i);
			indices.erase(indices.begin()+i);
			--i; // To counter increment we don't want here
			break;  // Out of j-while
		} // Now both are droppable; keep one with most independent, j loses if equal
				else
		{ if (countI >= countJ)
				{ printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
					candList.erase(candList.begin()+j);
					indices.erase(indices.begin()+j);
				}
			else // Drop i
				{ printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					candList.erase(candList.begin()+i);
					indices.erase(indices.begin()+i);
					--i; // To counter increment we don't want here
					break;  // Out of j-while
				}
		}
			}
	}
			++i;
		}
					
	for (i = 0; i<indices.size(); ++i)
		{ vecTracksFiltered.push_back(vecTracks.at(indices[i])); // copy non-dupes to output
		}

	return vecTracksFiltered;
}



// A specific algorithm for filtering duplicates
// Cut on ChiSq of linear fit in RZ -- experimental, didn't work well
// Filter on reduced ChiSq of a linear fit in RZ

template <class T>
vector<T> KillDupTrks<T>::filterAlg4(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector<double> myR, myZ;
		
		for (const auto & myStub: stubs)
		{
			myR.push_back(myStub->r());
			myZ.push_back(myStub->z());
		}
		
		double c0_,c1_,cov00_,cov01_,cov11_,chiSq_; // For gsl_fit_linear
		gsl_fit_linear(&myZ[0], 1, &myR[0], 1, myZ.size(), &c0_, &c1_, &cov00_, &cov01_, &cov11_, &chiSq_);
		
		if (chiSq_/(myZ.size()-2) <= dupTrkChiSqCut_)
		{
			vecTracksFiltered.push_back(trk);
		}
	}
	
	return vecTracksFiltered;
}



// A specific algorithm for filtering duplicates
// Pairwise candidate comparison, if two have at least N common stubs in N layers, keep (smaller) larger
// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep /*smallest*/ longest! candidates if common stubs in N or more layers (default 5 at present)

template <class T>
vector<T> KillDupTrks<T>::filterAlg5(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< std::pair<unsigned int, unsigned int> > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned int, unsigned int> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned int,unsigned int >( myStub->index(), myStub->layerId() ) );
		}
		
		// now necessary due to seed-filter disordering stubs; looks like pair sort is logical...
		std::sort(stubList.begin(),stubList.end());
		
		candList.push_back(stubList);
	}
	
	// to avoid expense of manipulating candidate vector
	std::vector< unsigned int > indices;
	
	for (std::size_t i = 0; i < candList.size(); ++i)
	{
		indices.push_back(i);
	}
	
	unsigned int i = 0;
	
	 // Loop through vector
	while ( i < (candList.size() - 1) )
	{
		unsigned int j = i+1;
		
		 // Check rest of candidates
		while ( j < candList.size() )
		{
			unsigned int match = 0;
			unsigned int indxI = 0;
			unsigned int indxJ = 0;
			unsigned int lenI = candList[i].size();
			unsigned int lenJ = candList[j].size();
			
			std::set<unsigned int> layers;
			
			while ( (indxI < lenI) && (indxJ < lenJ) )
			{
				// Stub indices match?
				if (candList[i][indxI].first == candList[j][indxJ].first)
				{
					// Get layer for stub
					unsigned int layer = candList[i][indxI].second;
					
					// Any match in this layer yet?
					if (layers.insert(layer).second)
					{
						++match;
					}
					
					// Next stubs
					++indxI;
					++indxJ;
				} 
				else
				{
					if (candList[i][indxI].first < candList[j][indxJ].first)
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			// Enough in common to keep one
			if (match >= dupTrkMinCommonHitsLayers_)
			{
				// Keep longer, works better!
				if (lenI <= lenJ)
				{
					//printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					
					candList.erase(candList.begin()+i);
					indices.erase(indices.begin()+i);
					
					// To counter increment we don't want here
					--i;
					
					// Out of j-while
					break;
				}
				else  // Delete j
				{
					//printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
					
					candList.erase(candList.begin()+j);
					indices.erase(indices.begin()+j);
				}
			}
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		
		++i;
	}
	
	for (std::size_t i = 0; i < indices.size(); ++i)
	{
		// copy non-dupes to output
		vecTracksFiltered.push_back(vecTracks.at(indices[i]));
	}

	return vecTracksFiltered;
}



//  A specific algorithm for filtering duplicates
// Pairwise candidate comparison, if two have at least N common stubs in N layers, keep one with smaller RZ/ZR red chisq
// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep smallest candidates if common stubs in N or more layers (default 5 at present)
// Try keeping track with best RZ/ZR reduced chi-square

template <class T>
vector<T> KillDupTrks<T>::filterAlg6(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< std::pair<unsigned int, unsigned int> > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned int, unsigned int> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned int,unsigned int >( myStub->index(), myStub->layerId() ) );
		}
		
		// now necessary due to seed-filter disordering stubs
		std::sort(stubList.begin(),stubList.end());
		
		candList.push_back(stubList);
	}
	
	
	// to avoid expense of manipulating candidate vector
	std::vector< unsigned int > indices;
	
	for (std::size_t i = 0; i < candList.size(); ++i)
	{
		indices.push_back(i);
	}
	
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (candList.size() - 1) )
	{
		unsigned int j = i + 1;
		
		// Check rest of candidates
		while (j < candList.size())
		{
			unsigned int match = 0;
			
			unsigned int indxI = 0;
			unsigned int indxJ = 0;
			
			unsigned int lenI = candList[i].size();
			unsigned int lenJ = candList[j].size();
			
			std::set<unsigned int> layers;
			while
			(
				(indxI < lenI)
				&&
				(indxJ < lenJ)
			)
			{
				if ( candList[i][indxI].first == candList[j][indxJ].first )
				{
					// Stub indices match
					
					// Get layer for stub
					unsigned int layer = candList[i][indxI].second;
					
					// Any match in this layer yet?
					if (layers.insert(layer).second)
					{
						++match;
					}
					
					// Next stubs
					++indxI;
					++indxJ;
				}
				else
				{
					if (candList[i][indxI].first < candList[j][indxJ].first)
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			// Enough in common to keep one
			if (match >= dupTrkMinCommonHitsLayers_)
			{
				double minIchisq, iChisq, minJchisq, jChisq;

				double c0_,c1_,cov00_,cov01_,cov11_,chiSq_; // For gsl_fit_linear
				
				const vector< const Stub * > &  stubs = vecTracks[i].getStubs();
				
				std::vector<double> myR, myZ;
				
				
				
				for (const auto & myStub: stubs)
				{
					myR.push_back(myStub->r());
					myZ.push_back(myStub->z());
				}
				
				gsl_fit_linear(&myZ[0], 1, &myR[0], 1, myZ.size(), &c0_, &c1_, &cov00_, &cov01_, &cov11_, &minIchisq);
				
				minIchisq = minIchisq/(myZ.size()-2);
				
				gsl_fit_linear(&myR[0], 1, &myZ[0], 1, myZ.size(), &c0_, &c1_, &cov00_, &cov01_, &cov11_, &iChisq);
				
				iChisq = iChisq/(myZ.size()-2);
				
				if (iChisq < minIchisq)
				{
					minIchisq = iChisq;
				}
				
				const vector< const Stub * > &  stubsj = vecTracks[j].getStubs();
				
				std::vector<double> myRj;
				std::vector<double> myZj;
				
				for (const auto & myStub: stubsj)
				{
					myRj.push_back(myStub->r());
					myZj.push_back(myStub->z());
				}
				
				gsl_fit_linear(&myZj[0], 1, &myRj[0], 1, myZj.size(), &c0_, &c1_, &cov00_, &cov01_, &cov11_, &minJchisq);
				
				minJchisq = minJchisq / ( myZj.size() - 2 );
				
				if (minJchisq > minIchisq)
				{
					gsl_fit_linear(&myRj[0], 1, &myZj[0], 1, myZj.size(), &c0_, &c1_, &cov00_, &cov01_, &cov11_, &jChisq);
					
					jChisq = jChisq / ( myZj.size() - 2 );
					
					if (jChisq < minJchisq)
					{
						minJchisq = jChisq;
					}
				}
				
				// Keep smallest reduced chisq, prefer i if equal
				if (minIchisq > minJchisq)
				{
					//printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					
					candList.erase(candList.begin()+i);
					indices.erase(indices.begin()+i);
					
					// To counter increment we don't want here
					--i;
					
					// Out of j-while
					break;
				}
				else
				{
					// Delete j
					//printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
					
					candList.erase(candList.begin()+j);
					indices.erase(indices.begin()+j);
				}
			} 
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		
		++i;
	}
	
	for (std::size_t i = 0; i < indices.size(); ++i)
	{
		// copy non-dupes to output
		vecTracksFiltered.push_back(vecTracks.at(indices[i]));
	}
	
	return vecTracksFiltered;
}



//  A specific algorithm for filtering duplicates
// Pairwise candidate comparison, if two have at least N common stubs in N layers, keep one with best "quality"
// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep "best"((c) IanT 2015) candidates if common stubs in N or more layers (default 5 at present)

template <class T>
vector<T> KillDupTrks<T>::filterAlg7(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< std::pair<unsigned int, unsigned int> > > candList; 
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned int, unsigned int> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned int,unsigned int >( myStub->index(), myStub->layerId() ) );
		}
		
		// now necessary due to seed-filter disordering stubs
		std::sort(stubList.begin(),stubList.end());
		
		candList.push_back(stubList);
	}
	
	
	
	std::vector< unsigned int > indices; // to avoid expense of manipulating candidate vector
	for (std::size_t i = 0; i < candList.size(); ++i)
	{
		indices.push_back(i);
	}
	
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (candList.size() - 1) )
	{
		unsigned int j = i+1;
		
		while (j < candList.size()) // Check rest of candidates
		{
			unsigned int match = 0;
			
			unsigned int indxI = 0;
			unsigned int indxJ = 0;
			
			unsigned int lenI = candList[i].size();
			unsigned int lenJ = candList[j].size();
			
			std::set<unsigned int> layers;
			
			while ((indxI<lenI) && (indxJ<lenJ))
			{
				if (candList[i][indxI].first == candList[j][indxJ].first) // Stub indices match?
				{
					unsigned int layer = candList[i][indxI].second; // Get layer for stub
					
					if (layers.insert(layer).second) // Any match in this layer yet?
					{
						++match;
					}
					
					// Next stubs
					++indxI;
					++indxJ;
				} 
				else
				{
					if (candList[i][indxI].first < candList[j][indxJ].first)
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			if (match >= dupTrkMinCommonHitsLayers_) // Enough in common to keep one
			{
				unsigned int qualI = 1000 * vecTracks[ indices[i] ].getNumLayers() + vecTracks[ indices[i] ].getNumStubs();
				unsigned int qualJ = 1000 * vecTracks[ indices[j] ].getNumLayers() + vecTracks[ indices[j] ].getNumStubs();
				
				// Keep best "quality"
				if (qualI <= qualJ)
				{
					// Delete i
					//printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					
					candList.erase(candList.begin()+i);
					indices.erase(indices.begin()+i);
					
					// To counter increment we don't want here
					--i;
					
					// Out of j-while
					break;
				}
				else
				{
					// Delete j
					//printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
					
					candList.erase(candList.begin()+j);
					indices.erase(indices.begin()+j);
				}
			}
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		
		++i;
	}
	
	for (std::size_t i = 0; i < indices.size(); ++i)
	{
		vecTracksFiltered.push_back(vecTracks.at( indices[i] )); // copy non-dupes to output
	}
	
	return vecTracksFiltered;
}



// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep largest candidates if common stubs in N or more layers (default 5 at present), both if equal
// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep largest candidates if common stubs in N or more layers (default 5 at present), both if equal

template <class T>
vector<T> KillDupTrks<T>::filterAlg8(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< std::pair<unsigned int, unsigned int> > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		std::vector< std::pair<unsigned int, unsigned int> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned int,unsigned int >( myStub->index(), myStub->layerId() ) );
		}
		
		// now necessary due to seed-filter disordering stubs
		std::sort(stubList.begin(),stubList.end());
		
		// make up vector of vectors
		candList.push_back(stubList);
	}
	
	std::vector< unsigned int > indices; // to avoid expense of manipulating candidate vector
	
	for (std::size_t i = 0; i < candList.size(); ++i)
	{
		indices.push_back(i);
	}
	
	
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (candList.size() - 1) )
	{
		unsigned int j = i + 1;
		
		// Check rest of candidates
		while (j < candList.size() )
		{
			unsigned int match = 0, indxI = 0, indxJ = 0;
			unsigned int lenI = candList[i].size(), lenJ = candList[j].size();
			std::set<unsigned int> layers;
			
			while ((indxI<lenI) && (indxJ<lenJ))
			{
				// Stub indices match?
				if ( candList[i][indxI].first == candList[j][indxJ].first )
				{
					// Get layer for stub
					unsigned int layer = candList[i][indxI].second;
					
					if (layers.insert(layer).second) // Any match in this layer yet?
					{
						++match;
					}
					
					// Next stubs
					++indxI;
					++indxJ;
				} 
				else
				{
					if ( candList[i][indxI].first < candList[j][indxJ].first )
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			if (match >= dupTrkMinCommonHitsLayers_) // Enough in common to keep one and kill the other
			{
				unsigned int qualI = vecTracks[ indices[i] ].getNumLayers();
				unsigned int qualJ = vecTracks[ indices[j] ].getNumLayers();
				
				// Keep best "quality"
				if (qualI < qualJ)
				{
					printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					
					candList.erase(candList.begin()+i);
					indices.erase(indices.begin()+i);
					
					// To counter increment we don't want here
					--i;
					
					// Out of j-while
					break;
				}
				else
				{
					// Delete j if lower quality (or equal to remove duplicates!)
					
					printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
					
					candList.erase(candList.begin()+j);
					indices.erase(indices.begin()+j);
				}
			} 
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		++i;
	}
	
	for (std::size_t i = 0; i < indices.size(); ++i)
	{
		vecTracksFiltered.push_back(vecTracks.at(indices[i])); // copy non-dupes to output
	}
	
	return vecTracksFiltered;
}




// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep smallest candidates if common stubs in N or more layers (default 5 at present),
// Didn't work, back to Alg8 for present...
// later add keep least stubs if equal
// Implementing "inverse" OSU algorithm, check for stubs in common,
// Try keeping _smallest_; Nope, didn't work, back to original Alg8
// (later -- if equal, keep least no of stubs), if still equal discard one (otherwise dupes not removed)

template <class T>
vector<T> KillDupTrks<T>::filterAlg9(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	// vector (corresponding to candidate tracks) of vectors (indices for stubs)
	std::vector< std::vector< std::pair<unsigned int, unsigned int> > > candList;
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned int, unsigned int> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned int,unsigned int >( myStub->index(), myStub->layerId() ) );
		}
		
		std::sort(stubList.begin(),stubList.end()); // now necessary due to seed-filter disordering stubs
		
		candList.push_back(stubList);
	}
	
	std::vector< unsigned int > indices; // to avoid expense of manipulating candidate vector
	
	for (std::size_t i = 0; i < candList.size(); ++i)
	{
		indices.push_back(i);
	}
	
	
	
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (candList.size() - 1) )
	{
		unsigned int j = i+1;
		
		// Check rest of candidates
		while (j < candList.size())
		{
			unsigned int match = 0, indxI = 0, indxJ = 0;
			
			unsigned int lenI = candList[i].size(), lenJ = candList[j].size();
			
			std::set<unsigned int> layers;
			
			while ( (indxI < lenI) && (indxJ < lenJ) )
			{
				// Stub indices match?
				if (candList[i][indxI].first == candList[j][indxJ].first)
				{
					// Get layer for stub
					unsigned int layer = candList[i][indxI].second;
					
					// Any match in this layer yet?
					if (layers.insert(layer).second)
					{
						++match;
					}
					
					// Next stubs
					++indxI;
					++indxJ;
				}
				else
				{
					if ( candList[i][indxI].first < candList[j][indxJ].first )
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			// Enough in common to keep one
			if (match >= dupTrkMinCommonHitsLayers_)
			{
				unsigned int qualI = vecTracks[ indices[i] ].getNumLayers();
				unsigned int qualJ = vecTracks[ indices[j] ].getNumLayers();
				
				// Keep best "quality"
				if (qualI < qualJ)
				{
					printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
					
					candList.erase(candList.begin()+i);
					
					indices.erase(indices.begin()+i);
					
					// To counter increment we don't want here
					--i;
					
					// Out of j-while
					break;
				}
				else
				{ 
					if (qualJ < qualI)
					{
						// Delete j if lower quality
						printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
						
						candList.erase(candList.begin()+j);
						
						indices.erase(indices.begin()+j);
					}
					else
					{
						//equal, let's try keeping the smallest
						qualI = vecTracks[ indices[i] ].getNumStubs();
						qualJ = vecTracks[ indices[j] ].getNumStubs();
						
						// i has more stubs
						if (qualJ <= qualI)
						{
							printKill(dupTrkAlg_, i, j, vecTracks[ indices[i] ], vecTracks[ indices[j] ]);
							
							candList.erase(candList.begin()+i);
							indices.erase(indices.begin()+i);
							
							// To counter increment we don't want here
							--i;
							
							// Out of j-while
							break;
						}
						else
						{
							printKill(dupTrkAlg_, j, i, vecTracks[ indices[j] ], vecTracks[ indices[i] ]);
							
							candList.erase(candList.begin()+j);
							indices.erase(indices.begin()+j);
						}
					}
				}
			} 
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		
		++i;
	}
	
	for (i = 0; i<indices.size(); ++i)
		{ vecTracksFiltered.push_back(vecTracks.at(indices[i])); // copy non-dupes to output
		}

	return vecTracksFiltered;
}



// Try just removing r-phi candidates in adjacent cells as dupes are mostly adjacent

template <class T>
vector<T> KillDupTrks<T>::filterAlg10(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (vecTracksFiltered.size() - 1) )
	{
		unsigned int j = i + 1;
		
		std::pair<unsigned int, unsigned int> canloc = vecTracksFiltered[i].getCellLocationRphi();
		
		// Check rest of candidates
		while (j < vecTracksFiltered.size())
		{
			if
			  (
			   isAdjacentCell(canloc,vecTracksFiltered[j].getCellLocationRphi())
			   )
			{
				printKill(dupTrkAlg_,  j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
				
				// remove duplicate
				vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
			}
			else
			{
				//try next candidate
				++j;
			}
		}
		
		// compared all, now look for dupes of next candidate
		++i;
	}
	return vecTracksFiltered;
}



// Try just removing r-phi candidates in adjacent cells *with same number of stubs* as dupes are mostly adjacent
template <class T>
vector<T> KillDupTrks<T>::filterAlg11(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place	
	
	unsigned int i = 0;
	
	while ( i < (vecTracksFiltered.size() - 1) ) // Loop through vector
	{
		// Do a triangular loop (saves [1/2 matrix + diagonal] operations)
		unsigned int j = i + 1;
		
		std::pair<unsigned int, unsigned int> canloc = vecTracksFiltered[i].getCellLocationRphi();
		unsigned int nStubs = vecTracksFiltered[i].getNumStubs();
		
		while (j < vecTracksFiltered.size()) // Check rest of candidates
		{
			if
			(
				( nStubs == vecTracksFiltered[j].getNumStubs() )
				&& 
				isAdjacentCell(canloc,vecTracksFiltered[j].getCellLocationRphi())
			)
			{
				printKill(dupTrkAlg_,  j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
				
				// remove duplicate
				vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
			}
			else
			{
				//try next candidate
				++j;
			}
		}
		
		// compared all, now look for dupes of next candidate
		++i;
	}
	return vecTracksFiltered;
}



// Try just removing r-phi candidates in adjacent cells in X (with same number of stubs) as dupes are mostly adjacent

template <class T>
vector<T> KillDupTrks<T>::filterAlg12(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place		
	
	unsigned int i = 0;
	
	while ( i < (vecTracksFiltered.size() - 1) ) // Loop through vector
	{
		// Do a triangular loop (saves [1/2 matrix + diagonal] operations)
		unsigned int j = i + 1;
		
		std::pair<unsigned int, unsigned int> canloc = vecTracksFiltered[i].getCellLocationRphi();
		unsigned int nStubs =  vecTracksFiltered[i].getNumStubs();

		while (j < vecTracksFiltered.size()) // Check rest of candidates
		{
			if
			(
				( nStubs == vecTracksFiltered[j].getNumStubs() )
				&& 
				 isNextQoverPt(canloc,vecTracksFiltered[j].getCellLocationRphi())
			)
			{
				printKill(dupTrkAlg_,  j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
				
				// remove duplicate
				vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
			}
			else
			{
				//try next candidate
				++j;
			}
		}
		
		// compared all, now look for dupes of next candidate
		++i;
	}
	
	return vecTracksFiltered;
}



// Try just merging r-phi candidates in adjacent cells in X

template <class T>
vector<T> KillDupTrks<T>::filterAlg13(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place		
	
	unsigned int i = 0;
	
	// Loop through vector
	while ( i < (vecTracksFiltered.size() - 1) )
	{
		// Do a triangular loop (saves [1/2 matrix + diagonal] operations)
		unsigned int j = i + 1;
		
		// canloc contains (col, row) pairs
		std::pair<unsigned int, unsigned int> canloc = vecTracksFiltered[i].getCellLocationRphi();
		
		// Check rest of candidates
		while (j < vecTracksFiltered.size())
		{
		  if ( isNextQoverPt(canloc,vecTracksFiltered[j].getCellLocationRphi() ) )
		    {
		      printKill(dupTrkAlg_,  j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
		      
		      vecTracksFiltered[i] = vecTracksFiltered[i].mergeTracks(vecTracksFiltered[j]);
		      // remove duplicate
		      vecTracksFiltered.erase(vecTracksFiltered.begin()+j);

		      break; // only one possibility so skip rest
		    }
		  else
		    {
		      // try next candidate
		      ++j;
		    }
		}

		// compared all, now look for dupes of next candidate
		++i;
	}
	return vecTracksFiltered;
}



// Try merging r-phi candidates in all adjacent cells

template <class T>
vector<T> KillDupTrks<T>::filterAlg14(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place		
	
	unsigned int i = 0;
	
	while ( i < (vecTracksFiltered.size() - 1) ) // Loop through vector
	{
		unsigned int j = i+1;
		
		std::pair<unsigned int, unsigned int> canloc = vecTracksFiltered[i].getCellLocationRphi();
		
		T iCandidate = vecTracksFiltered[i]; // Need to carry object through the loop
		
		while (j < vecTracksFiltered.size()) // Check rest of candidates
		{
			if
				(
				 isAdjacentCell(canloc, vecTracksFiltered[j].getCellLocationRphi())
				) // adjacent, merge
			{
				printKill(dupTrkAlg_,  j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
				
				iCandidate = iCandidate.mergeTracks(vecTracksFiltered[j]);
				
				// remove duplicate
				vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
			}
			else
			{
				//try next candidate
				++j;
			}
		}
		
		// save (possibly) merged candidate
		vecTracksFiltered[i] = iCandidate;
		
		++i; // compared all, now look for dupes of next candidate
		
	}
	
	return vecTracksFiltered;
}



// Implementing "inverse" OSU algorithm, check for stubs in common,
// keep largest candidates if common stubs in N or more layers (default 5 at present), drop second if equal

template <class T>
vector<T> KillDupTrks<T>::filterAlg15(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
	std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place
	
	int nCands = vecTracks.size();
	int nComps = 0;
	
	std::vector< std::vector< std::pair<unsigned, unsigned> > > candList; // to store stub index()s
	
	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned, unsigned> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned,unsigned >( myStub->index(), myStub->layerId() ) );
		}
		
		std::sort(stubList.begin(),stubList.end()); // now necessary due to seed-filter disordering stubs
		
		candList.push_back(stubList); // make up vector of vectors
		
	}
	
	// check for duplicates
	unsigned  int i = 0;
	while (i < (candList.size() - 1)) // Loop through vector
	{
		unsigned int j = i + 1;
		
		float thisPt   = vecTracksFiltered[i].qOverPt() + dupMaxQOverPtScan_; //now a parameter...
		float thisPhi0 = vecTracksFiltered[i].phi0();
		float thisZ0   = vecTracksFiltered[i].z0();
		float thisTanl = vecTracksFiltered[i].tanLambda();
		
		while (j < candList.size()) // Check rest of candidates
		  { if (vecTracksFiltered[j].qOverPt() > thisPt) break;  //limit Pt range
		    if (fabs(thisPhi0 - vecTracksFiltered[j].phi0()) > dupMaxPhi0Scan_) {++j; continue;} //now a parameter...
		    if (fabs(thisZ0   - vecTracksFiltered[j].z0())   > dupMaxZ0Scan_) {++j; continue;}
		    if (fabs(thisTanl - vecTracksFiltered[j].tanLambda()) > dupMaxTanLambdaScan_) {++j; continue;}
			
		    ++nComps;
		    
		    unsigned int match = 0;
		    unsigned int indxI = 0;
		    unsigned int indxJ = 0;
		    unsigned int lenI = candList[i].size();
		    unsigned int lenJ = candList[j].size();
		    unsigned int stubmatch = 0;
			
		    std::set<unsigned> layers;
			
			while ( (indxI<lenI) && (indxJ<lenJ) )
			  { 
				if ( candList[i][indxI].first == candList[j][indxJ].first ) // Stub indices match?
				{
					unsigned layer = candList[i][indxI].second; // Get layer for stub
					if (layers.insert(layer).second) // Any match in this layer yet?
					{
						++match;
					}
					
					++stubmatch;  // Counting matched stubs
					++indxI; ++indxJ;  // Next stubs
				} 
				else
				{
					if (candList[i][indxI].first < candList[j][indxJ].first)
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			if (match >= dupTrkMinCommonHitsLayers_) // Enough in common to keep one
			{
				unsigned int qualI = vecTracksFiltered[i].getNumLayers();
				unsigned int qualJ = vecTracksFiltered[j].getNumLayers();
				
				if (qualI < qualJ) // Keep best "quality"
				{
					printKill(dupTrkAlg_, i, j, vecTracksFiltered[i], vecTracksFiltered[j]);
					candList.erase(candList.begin()+i);
					vecTracksFiltered.erase(vecTracksFiltered.begin()+i);
					--i; // To counter increment we don't want here
					break;  // Out of j-while
				}
				else  // Delete j if lower quality (or equal to remove duplicates!)
				{
					printKill(dupTrkAlg_, j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
					candList.erase(candList.begin()+j);
					vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
				}
			} 
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
			
		++i;
	}
	
	//	std::cout << "Alg 15: " << nCands << " candidates, " << nComps << " comparisons" << std::endl;
	
	return vecTracksFiltered;
}

// Implementing "inverse" OSU algorithm, check for stubs in common,
// merge candidates if common stubs in N or more layers (default 5 at present)

template <class T>
vector<T> KillDupTrks<T>::filterAlg16(const vector<T>& vecTracks) const
{
  vector<T> vecTracksFiltered = vecTracks; // vecTracks no longer sorted by signed q/pT
  std::sort(vecTracksFiltered.begin(), vecTracksFiltered.end(),  T::qOverPtSortPredicate);  // We can do this in-place

	int nCands = vecTracks.size();
	int nComps = 0;

	std::vector< std::vector< std::pair<unsigned, unsigned> > > candList; // to store stub index()s

	for (const T& trk : vecTracks)
	{
		const vector< const Stub * > &  stubs = trk.getStubs();
		
		std::vector< std::pair<unsigned, unsigned> > stubList;
		
		for (const auto & myStub: stubs)
		{
			stubList.push_back( std::pair< unsigned,unsigned >( myStub->index(), myStub->layerId() ) );
		}
		
		std::sort(stubList.begin(), stubList.end()); // now necessary due to seed-filter disordering stubs
		
		candList.push_back(stubList); // make up vector of vectors
	}
	
	// check for duplicates
	unsigned int i = 0;
	
	while (i < (candList.size()-1)) // Loop through vector
	{
		unsigned j = i+1;
		float thisPt   = vecTracksFiltered[i].qOverPt() + dupMaxQOverPtScan_; //now a parameter...
		float thisPhi0 = vecTracksFiltered[i].phi0();
		float thisZ0   = vecTracksFiltered[i].z0();
		float thisTanl = vecTracksFiltered[i].tanLambda();
		T iCandidate   = vecTracksFiltered[i]; // Need to carry object through the loop
		while (j < candList.size()) // Check rest of candidates
		{
			if (vecTracksFiltered[j].qOverPt() > thisPt) break;  //limit Pt range
			if (fabs(thisPhi0 - vecTracksFiltered[j].phi0()) > dupMaxPhi0Scan_) {++j; continue;} //now a parameter...
			if (fabs(thisZ0   - vecTracksFiltered[j].z0())   > dupMaxZ0Scan_)   {++j; continue;}
			if (fabs(thisTanl - vecTracksFiltered[j].tanLambda()) > dupMaxTanLambdaScan_) {++j; continue;}
			
			++nComps;
			
			unsigned int match = 0;
			unsigned int indxI = 0;
			unsigned int indxJ = 0;
			unsigned int stubmatch = 0;
			unsigned int lenI = candList[i].size();
			unsigned int lenJ = candList[j].size();
			
			std::set<unsigned> layers;
			
			while ( (indxI < lenI) && (indxJ < lenJ) )
			{
				if ( candList[i][indxI].first == candList[j][indxJ].first ) // Stub indices match?
				{
					unsigned layer = candList[i][indxI].second; // Get layer for stub
					
					if (layers.insert(layer).second) // Any match in this layer yet?
					{
						++match;
					}
					
					++stubmatch; //counting stubs as well as layers
					++indxI; ++indxJ;  // Next stubs
				} 
				else
				{
					if (candList[i][indxI].first < candList[j][indxJ].first)
					{
						// In i, not j
						++indxI;
					}
					else
					{
						// In j, not i
						++indxJ;
					}
				}
			}
			
			if (match >= dupTrkMinCommonHitsLayers_) // Enough in common so merge
			{
				printKill(dupTrkAlg_, j, i, vecTracksFiltered[j], vecTracksFiltered[i]);
				
				iCandidate = iCandidate.mergeTracks(vecTracksFiltered[j]);
				
				const vector< const Stub * > &  stubs = iCandidate.getStubs(); // Update candList!
				
				std::vector< std::pair<unsigned, unsigned> > stubList;
				
				for (const auto & myStub: stubs)
				{
					stubList.push_back( std::pair< unsigned,unsigned >( myStub->index(), myStub->layerId() ) );
				}
				
				std::sort(stubList.begin(),stubList.end()); // Should be ordered after merge, but still...
				
				candList[i] = stubList; // Insert merged stub list
				candList.erase(candList.begin()+j);
				vecTracksFiltered.erase(vecTracksFiltered.begin()+j);
			} 
			else
			{
				// Keep both, next candidate
				++j;
			}
		}
		vecTracksFiltered[i] = iCandidate; // save (possibly) merged candidate
		
		++i;
		
	}
	
	//	std::cout << "Alg 16: " << nCands << " candidates, " << nComps << " comparisons" << std::endl;
	
	return vecTracksFiltered;
}

// Duplicate removal -- merge candidates within tight cuts on helix parameters
// Best results for 32x32 HT for cuts corresponding to adjacent HT cells
template <class T>
vector<T> KillDupTrks<T>::filterAlg17(const vector<T>& vecTracks) const
{ vector<T> vecTracksSorted = vecTracks; // vecTracks no longer sorted by signed q/pT
  std::sort(vecTracksSorted.begin(), vecTracksSorted.end(),  T::qOverPtSortPredicate);

  unsigned i=0;
  while (i < (vecTracksSorted.size()-1)) // Loop through vector
    { unsigned j = i+1;
      float thisPt   = vecTracksSorted[i].qOverPt() + dupMaxQOverPtScan_; //now a parameter...
      float thisPhi0 = vecTracksSorted[i].phi0();
      float thisZ0   = vecTracksSorted[i].z0();
      float thisTanl = vecTracksSorted[i].tanLambda();
      T iCandidate   = vecTracksSorted[i]; // Need to carry object through the loop
      while (j < vecTracksSorted.size()) // Check rest of candidates
	{ if (vecTracksSorted[j].qOverPt() > thisPt) break;  //limit Pt range
	  if (fabs(thisPhi0 - vecTracksSorted[j].phi0()) > dupMaxPhi0Scan_) {++j; continue;} //now a parameter...
	  if (fabs(thisZ0   - vecTracksSorted[j].z0())   > dupMaxZ0Scan_)   {++j; continue;}
	  if (fabs(thisTanl - vecTracksSorted[j].tanLambda()) > dupMaxTanLambdaScan_) {++j; continue;}
	  
	  printKill(dupTrkAlg_, j, i, vecTracksSorted[j], vecTracksSorted[i]);
	  iCandidate = iCandidate.mergeTracks(vecTracksSorted[j]);
	  vecTracksSorted.erase(vecTracksSorted.begin()+j);
	}
      vecTracksSorted[i] = iCandidate; // save (possibly) merged candidate
      ++i;
    }
  
  return vecTracksSorted;
}

// Duplicate removal -- merge candidates in adjacent HT cells within tight cuts on other parameters
template <class T>
vector<T> KillDupTrks<T>::filterAlg18(const vector<T>& vecTracks) const
{ vector<T> vecTracksSorted = vecTracks; // vecTracks no longer sorted by signed q/pT
  std::sort(vecTracksSorted.begin(), vecTracksSorted.end(),  T::qOverPtSortPredicate);

  unsigned i=0;
  while (i < (vecTracksSorted.size()-1)) // Loop through vector
    { unsigned j = i+1;
      std::pair<unsigned int, unsigned int> canloc = vecTracksSorted[i].getCellLocationRphi();
      float thisZ0   = vecTracksSorted[i].z0();
      float thisTanl = vecTracksSorted[i].tanLambda();
      T iCandidate   = vecTracksSorted[i]; // Need to carry object through the loop
      while (j < vecTracksSorted.size()) // Check rest of candidates
	{ if (!isAdjacentCell(canloc, vecTracksSorted[j].getCellLocationRphi())) {++j; continue;}
	  if (fabs(thisZ0   - vecTracksSorted[j].z0())   > dupMaxZ0Scan_)   {++j; continue;}
	  if (fabs(thisTanl - vecTracksSorted[j].tanLambda()) > dupMaxTanLambdaScan_) {++j; continue;}
	  
	  printKill(dupTrkAlg_, j, i, vecTracksSorted[j], vecTracksSorted[i]);
	  iCandidate = iCandidate.mergeTracks(vecTracksSorted[j]);
	  vecTracksSorted.erase(vecTracksSorted.begin()+j);
	}
      vecTracksSorted[i] = iCandidate; // save (possibly) merged candidate
      ++i;
    }
  
  return vecTracksSorted;
}

// Duplicate removal -- drop "worst" candidate in adjacent HT cells within tight cuts on other parameters
template <class T>
vector<T> KillDupTrks<T>::filterAlg19(const vector<T>& vecTracks) const
{ vector<T> vecTracksSorted = vecTracks; // vecTracks no longer sorted by signed q/pT
  std::sort(vecTracksSorted.begin(), vecTracksSorted.end(),  T::qOverPtSortPredicate);

  unsigned i=0;
  while (i < (vecTracksSorted.size()-1)) // Loop through vector
    { unsigned j = i+1;
      std::pair<unsigned int, unsigned int> canloc = vecTracksSorted[i].getCellLocationRphi();
      float thisZ0   = vecTracksSorted[i].z0();
      float thisTanl = vecTracksSorted[i].tanLambda();
      //      unsigned int qualI = vecTracksSorted[i].getNumStubs();
      unsigned int qualI = vecTracksSorted[i].getNumLayers();
      while (j < vecTracksSorted.size()) // Check rest of candidates
	{ if (!isAdjacentCell(canloc, vecTracksSorted[j].getCellLocationRphi())) {++j; continue;}
	  if (fabs(thisZ0   - vecTracksSorted[j].z0())   > dupMaxZ0Scan_)   {++j; continue;}
	  if (fabs(thisTanl - vecTracksSorted[j].tanLambda()) > dupMaxTanLambdaScan_) {++j; continue;}

	  //	  if (qualI >= vecTracksSorted[j].getNumStubs()) // Try keeping one with most stubs
	  if (qualI >= vecTracksSorted[j].getNumLayers()) // Try keeping one with most stubs
	    { printKill(dupTrkAlg_, j, i, vecTracksSorted[j], vecTracksSorted[i]);
	      vecTracksSorted.erase(vecTracksSorted.begin()+j);
	    }
	  else
	    { printKill(dupTrkAlg_, i, j, vecTracksSorted[i], vecTracksSorted[j]);
	      vecTracksSorted.erase(vecTracksSorted.begin()+i);
	      --i; // Don't want to increment i
	      break; // Out of j-while
	    }
	}
      ++i;
    }
  
  return vecTracksSorted;
}

template <class T>
vector<T> KillDupTrks<T>::filterAlg100(const vector<T>& vecTracks) const
{
	vector<T> vecTracksFiltered;
	
	int nCands = vecTracks.size();
	int nComps = 0;
	
	for (const typename vector<T>::iterator iTrack = vecTracks.begin(), iTrackEnd = vecTracks.end(); iTrack < iTrackEnd; ++iTrack)
	{
		for (const typename vector<T>::iterator jTrack = iTrack + 1, jTrackEnd = vecTracks.end(); jTrack < jTrackEnd; ++jTrack)
		{
			
		}
	}
}


template <class T>
void KillDupTrks<T>::printKill(unsigned int alg, unsigned int dup, unsigned int cand, T dupTrack, T candTrack) const
{
	// condition to print debug info from duplicate track removal code.
	if (settings_->debug( ) == 5)
	{
		std::pair<unsigned int, unsigned int> duploc = dupTrack.getCellLocationRphi();
		std::pair<unsigned int, unsigned int> canloc = candTrack.getCellLocationRphi();
		
		const TP *dupTP=dupTrack.getMatchedTP(), *candTP=candTrack.getMatchedTP();
		
		int  dupTPIndex =  dupTP == nullptr ? -1 : dupTP->index();
		int candTPIndex = candTP == nullptr ? -1 : candTP->index(); 
		
		bool dupUsed = false, candUsed = false;
		
		if ( dupTP != nullptr) { dupUsed = dupTP->useForAlgEff();}
		if (candTP != nullptr) { candUsed = candTP->useForAlgEff();}

		std::cout
			<< "** Alg" << alg
			<< " erasing dupe " << dup << " (TP "<< dupTPIndex << " "<< dupUsed << ")" 
			<< " at (" << duploc.first << "," << duploc.second << ")" 
			<< " of cand " << cand << " (TP " << candTPIndex << " " << candUsed << ")"
			<< " at (" << canloc.first << "," << canloc.second << ")"
			<< " deltas " << int(duploc.first) - int(canloc.first) << " " << int(duploc.second) - int(canloc.second)
			<< std::endl;
	}
}

// I thought these three lines would allow the class implementation to be inside KillDupTrks.cc instead of in KillDupTrks.icc, but seems not to work ...
//template class KillDupTrks<L1track2D>;
//template class KillDupTrks<L1track3D>;
//template class KillDupTrks<L1fittedTrack>;
